{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>...</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>age</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>age_group</th>\n",
       "      <th>distance_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.703190e+15</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>Moravian Falls</td>\n",
       "      <td>NC</td>\n",
       "      <td>28654</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>...</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25-34</td>\n",
       "      <td>78.597568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.304230e+11</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>Orient</td>\n",
       "      <td>WA</td>\n",
       "      <td>99160</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>...</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35-44</td>\n",
       "      <td>30.212176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.885950e+13</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>Malad City</td>\n",
       "      <td>ID</td>\n",
       "      <td>83252</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>...</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55-64</td>\n",
       "      <td>108.206083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.534090e+15</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>MT</td>\n",
       "      <td>59632</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>...</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45-54</td>\n",
       "      <td>95.673231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.755340e+14</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>Doe Hill</td>\n",
       "      <td>VA</td>\n",
       "      <td>24433</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>...</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25-34</td>\n",
       "      <td>77.556744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cc_num                            merchant       category     amt  \\\n",
       "0  2.703190e+15          fraud_Rippin, Kub and Mann       misc_net    4.97   \n",
       "1  6.304230e+11     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23   \n",
       "2  3.885950e+13                fraud_Lind-Buckridge  entertainment  220.11   \n",
       "3  3.534090e+15  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00   \n",
       "4  3.755340e+14                 fraud_Keeling-Crist       misc_pos   41.96   \n",
       "\n",
       "  gender                        street            city state    zip      lat  \\\n",
       "0      F                561 Perry Cove  Moravian Falls    NC  28654  36.0788   \n",
       "1      F  43039 Riley Greens Suite 393          Orient    WA  99160  48.8878   \n",
       "2      M      594 White Dale Suite 530      Malad City    ID  83252  42.1808   \n",
       "3      M   9443 Cynthia Court Apt. 038         Boulder    MT  59632  46.2306   \n",
       "4      M              408 Bradley Rest        Doe Hill    VA  24433  38.4207   \n",
       "\n",
       "   ...  merch_lat  merch_long is_fraud age  year  month  hour  day_of_week  \\\n",
       "0  ...  36.011293  -82.048315        0  30  2019      1     0            1   \n",
       "1  ...  49.159047 -118.186462        0  40  2019      1     0            1   \n",
       "2  ...  43.150704 -112.154481        0  56  2019      1     0            1   \n",
       "3  ...  47.034331 -112.561071        0  51  2019      1     0            1   \n",
       "4  ...  38.674999  -78.632459        0  32  2019      1     0            1   \n",
       "\n",
       "   age_group  distance_km  \n",
       "0      25-34    78.597568  \n",
       "1      35-44    30.212176  \n",
       "2      55-64   108.206083  \n",
       "3      45-54    95.673231  \n",
       "4      25-34    77.556744  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('updatedcreditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape of X: (1048575, 24)\n",
      "Initial shape of y: (1048575,)\n",
      "Class distribution:\n",
      " is_fraud\n",
      "0    99.427223\n",
      "1     0.572777\n",
      "Name: proportion, dtype: float64 %\n",
      "\n",
      "=== FINAL SPLITS ===\n",
      "Train shape: (838860, 24) (838860,)\n",
      "Validation shape: (104857, 24) (104857,)\n",
      "Test shape: (104858, 24) (104858,)\n",
      "\n",
      "Train class distribution:\n",
      " is_fraud\n",
      "0    99.427199\n",
      "1     0.572801\n",
      "Name: proportion, dtype: float64 %\n",
      "Val class distribution:\n",
      " is_fraud\n",
      "0    99.427792\n",
      "1     0.572208\n",
      "Name: proportion, dtype: float64 %\n",
      "Test class distribution:\n",
      " is_fraud\n",
      "0    99.426844\n",
      "1     0.573156\n",
      "Name: proportion, dtype: float64 %\n",
      "\n",
      "[INFO] Shape of X_train_enc BEFORE SMOTE: (838860, 13)\n",
      "Class distribution in y_train_temp BEFORE SMOTE: [834055   4805]\n",
      "\n",
      "[INFO] Shape of X_train_enc AFTER SMOTE: (1668110, 13)\n",
      "Class distribution in y_train_sm AFTER SMOTE: [834055 834055]\n",
      "\n",
      "[DEBUG] Final Encoded Feature List (Train/Val/Test share):\n",
      "['amt', 'distance_km', 'age', 'city_pop', 'year', 'month', 'hour', 'day_of_week', 'gender_M', 'city_te', 'state_te', 'job_te', 'category_te']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 1) IMPORTS & SETUP\n",
    "# -----------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn / ML\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# XGBoost (CPU-based)\n",
    "import xgboost as xgb\n",
    "\n",
    "# RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Advanced encoding for high-cardinality or single-col cat\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# For synthetic sampling (SMOTE)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Optional progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2) CREATE A COPY OF DF -> comp_df AND SPLIT INTO TRAIN/VAL/TEST\n",
    "# -----------------------------------------------------------\n",
    "\"\"\"\n",
    "We assume your original DataFrame is named 'df' and has columns:\n",
    "   'category','amt','gender','city','state','city_pop','job',\n",
    "   'is_fraud','age','year','month','hour','day_of_week','distance_km',\n",
    "   etc. (adjust as needed).\n",
    "\n",
    "We will:\n",
    "   1) Make a copy: comp_df = df.copy()\n",
    "   2) Use comp_df in all subsequent transformations and modeling.\n",
    "\"\"\"\n",
    "\n",
    "# 2.1) Copy the original DataFrame\n",
    "comp_df = df.copy()\n",
    "\n",
    "# 2.2) Define the columns we actually need\n",
    "useful_cols = [\n",
    "    \"category\", \"amt\", \"gender\", \"city\", \"state\", \"city_pop\", \"job\",\n",
    "    \"is_fraud\", \"age\", \"year\", \"month\", \"hour\", \"day_of_week\", \n",
    "    \"distance_km\"\n",
    "]\n",
    "\n",
    "# 2.3) Clean: drop rows with missing data (if any)\n",
    "comp_df.dropna(subset=useful_cols, inplace=True)\n",
    "\n",
    "# 2.4) X / y\n",
    "X = comp_df.drop(columns=[\"is_fraud\"])\n",
    "y = comp_df[\"is_fraud\"].astype(int)\n",
    "\n",
    "print(\"Initial shape of X:\", X.shape)\n",
    "print(\"Initial shape of y:\", y.shape)\n",
    "print(\"Class distribution:\\n\", y.value_counts(normalize=True)*100, \"%\")\n",
    "\n",
    "# Split: 80% Train / 20% Temp\n",
    "X_train_temp, X_temp, y_train_temp, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# From the 20% Temp, split 50/50 => 10% Validation, 10% Test (of original data)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"\\n=== FINAL SPLITS ===\")\n",
    "print(\"Train shape:\", X_train_temp.shape, y_train_temp.shape)\n",
    "print(\"Validation shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "print(\"\\nTrain class distribution:\\n\", y_train_temp.value_counts(normalize=True)*100, \"%\")\n",
    "print(\"Val class distribution:\\n\", y_val.value_counts(normalize=True)*100, \"%\")\n",
    "print(\"Test class distribution:\\n\", y_test.value_counts(normalize=True)*100, \"%\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3) COLUMN GROUPS FOR ENCODING\n",
    "# -----------------------------------------------------------\n",
    "numeric_features = [\n",
    "    \"amt\", \"distance_km\", \"age\", \"city_pop\", \n",
    "    \"year\", \"month\", \"hour\", \"day_of_week\"\n",
    "]\n",
    "cat_small = [\"gender\"]                         # one-hot\n",
    "cat_high  = [\"city\",\"state\",\"job\",\"category\"]  # target-encode\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4) COLUMNTRANSFORMER (SCALING + ENCODING)\n",
    "# -----------------------------------------------------------\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "ohe_transformer = Pipeline([\n",
    "    (\"ohe\", OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "target_encoder = Pipeline([\n",
    "    (\"target_enc\", TargetEncoder(smoothing=0.3))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"ohe\", ohe_transformer, cat_small),\n",
    "        (\"te\",  target_encoder,  cat_high),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5) FIT PREPROCESSOR & APPLY SMOTE (TRAIN ONLY)\n",
    "# -----------------------------------------------------------\n",
    "X_train_enc = preprocessor.fit_transform(X_train_temp, y_train_temp)\n",
    "print(\"\\n[INFO] Shape of X_train_enc BEFORE SMOTE:\", X_train_enc.shape)\n",
    "print(\"Class distribution in y_train_temp BEFORE SMOTE:\", np.bincount(y_train_temp))\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train_enc, y_train_temp)\n",
    "\n",
    "print(\"\\n[INFO] Shape of X_train_enc AFTER SMOTE:\", X_train_sm.shape)\n",
    "print(\"Class distribution in y_train_sm AFTER SMOTE:\", np.bincount(y_train_sm))\n",
    "\n",
    "# Encode validation & test sets (do NOT refit)\n",
    "X_val_enc  = preprocessor.transform(X_val)\n",
    "X_test_enc = preprocessor.transform(X_test)\n",
    "\n",
    "# Build final feature name list\n",
    "ohe_step = preprocessor.named_transformers_['ohe'].named_steps['ohe']\n",
    "ohe_feature_names = ohe_step.get_feature_names_out(cat_small)\n",
    "te_cols = [f\"{col}_te\" for col in cat_high]\n",
    "final_feature_names = numeric_features + list(ohe_feature_names) + te_cols\n",
    "\n",
    "print(\"\\n[DEBUG] Final Encoded Feature List (Train/Val/Test share):\")\n",
    "print(final_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= RANDOM FOREST PIPELINE =================\n",
      "\n",
      "\n",
      "[DEBUG] Starting RFE fit (RandomForest) on TRAIN ONLY... (this may take a while)\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "\n",
      "[DEBUG] RandomForest RFE Feature Ranking Results:\n",
      "0: amt | Support=True, Rank=1\n",
      "1: distance_km | Support=False, Rank=3\n",
      "2: age | Support=True, Rank=1\n",
      "3: city_pop | Support=True, Rank=1\n",
      "4: year | Support=False, Rank=4\n",
      "5: month | Support=True, Rank=1\n",
      "6: hour | Support=True, Rank=1\n",
      "7: day_of_week | Support=True, Rank=1\n",
      "8: gender_M | Support=False, Rank=2\n",
      "9: city_te | Support=True, Rank=1\n",
      "10: state_te | Support=True, Rank=1\n",
      "11: job_te | Support=True, Rank=1\n",
      "12: category_te | Support=True, Rank=1\n",
      "\n",
      "=== SELECTED FEATURES by RandomForest RFE ===\n",
      "   - amt\n",
      "   - age\n",
      "   - city_pop\n",
      "   - month\n",
      "   - hour\n",
      "   - day_of_week\n",
      "   - city_te\n",
      "   - state_te\n",
      "   - job_te\n",
      "   - category_te\n",
      "\n",
      "[DEBUG] Training final RandomForest on selected features (TRAIN ONLY)...\n",
      "\n",
      "=== [RandomForest] MODEL PERFORMANCE ON TRAIN SET (WITH SMOTE) ===\n",
      "Accuracy (Train): 0.9999994005191504\n",
      "Classification Report (Train):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    834055\n",
      "           1       1.00      1.00      1.00    834055\n",
      "\n",
      "    accuracy                           1.00   1668110\n",
      "   macro avg       1.00      1.00      1.00   1668110\n",
      "weighted avg       1.00      1.00      1.00   1668110\n",
      "\n",
      "Confusion Matrix (Train):\n",
      " [[834055      0]\n",
      " [     1 834054]]\n",
      "\n",
      "=== [RandomForest] MODEL PERFORMANCE ON VALIDATION SET ===\n",
      "Accuracy (Val): 0.998321523598806\n",
      "Classification Report (Val):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    104257\n",
      "           1       0.88      0.82      0.85       600\n",
      "\n",
      "    accuracy                           1.00    104857\n",
      "   macro avg       0.94      0.91      0.92    104857\n",
      "weighted avg       1.00      1.00      1.00    104857\n",
      "\n",
      "Confusion Matrix (Val):\n",
      " [[104189     68]\n",
      " [   108    492]]\n",
      "\n",
      "=== [RandomForest] MODEL PERFORMANCE ON TEST SET ===\n",
      "Accuracy (Test): 0.9985885673959068\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    104257\n",
      "           1       0.91      0.84      0.87       601\n",
      "\n",
      "    accuracy                           1.00    104858\n",
      "   macro avg       0.95      0.92      0.94    104858\n",
      "weighted avg       1.00      1.00      1.00    104858\n",
      "\n",
      "Confusion Matrix (Test):\n",
      " [[104205     52]\n",
      " [    96    505]]\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# PART B: RANDOM FOREST (for comparison)\n",
    "# ===========================================================\n",
    "print(\"\\n================= RANDOM FOREST PIPELINE =================\\n\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# B.1) RFE USING RANDOMFOREST ON TRAIN\n",
    "# -----------------------------------------------------------\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # parallel\n",
    ")\n",
    "\n",
    "rf_rfe = RFE(\n",
    "    estimator=rf_clf,\n",
    "    n_features_to_select=10,\n",
    "    step=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n[DEBUG] Starting RFE fit (RandomForest) on TRAIN ONLY... (this may take a while)\")\n",
    "rf_rfe.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "rf_support_mask = rf_rfe.support_\n",
    "rf_ranking = rf_rfe.ranking_\n",
    "\n",
    "print(\"\\n[DEBUG] RandomForest RFE Feature Ranking Results:\")\n",
    "for i, feat_name in enumerate(final_feature_names):\n",
    "    print(f\"{i}: {feat_name} | Support={rf_support_mask[i]}, Rank={rf_ranking[i]}\")\n",
    "\n",
    "rf_selected_features = [f for f, s in zip(final_feature_names, rf_support_mask) if s]\n",
    "print(\"\\n=== SELECTED FEATURES by RandomForest RFE ===\")\n",
    "for feat in rf_selected_features:\n",
    "    print(\"   -\", feat)\n",
    "\n",
    "X_train_sel_rf = rf_rfe.transform(X_train_sm)\n",
    "X_val_sel_rf   = rf_rfe.transform(X_val_enc)\n",
    "X_test_sel_rf  = rf_rfe.transform(X_test_enc)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# B.2) TRAIN FINAL RANDOMFOREST ON SELECTED FEATURES (TRAIN ONLY)\n",
    "# -----------------------------------------------------------\n",
    "final_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\n[DEBUG] Training final RandomForest on selected features (TRAIN ONLY)...\")\n",
    "final_rf.fit(X_train_sel_rf, y_train_sm)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# B.3) EVALUATE ON TRAIN SET FIRST (OVERFITTING CHECK)\n",
    "# -----------------------------------------------------------\n",
    "rf_train_pred = final_rf.predict(X_train_sel_rf)\n",
    "rf_train_acc  = accuracy_score(y_train_sm, rf_train_pred)\n",
    "\n",
    "print(\"\\n=== [RandomForest] MODEL PERFORMANCE ON TRAIN SET (WITH SMOTE) ===\")\n",
    "print(\"Accuracy (Train):\", rf_train_acc)\n",
    "print(\"Classification Report (Train):\\n\", classification_report(y_train_sm, rf_train_pred))\n",
    "print(\"Confusion Matrix (Train):\\n\", confusion_matrix(y_train_sm, rf_train_pred))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# B.4) EVALUATE ON VALIDATION SET\n",
    "# -----------------------------------------------------------\n",
    "rf_val_pred = final_rf.predict(X_val_sel_rf)\n",
    "rf_val_acc = accuracy_score(y_val, rf_val_pred)\n",
    "\n",
    "print(\"\\n=== [RandomForest] MODEL PERFORMANCE ON VALIDATION SET ===\")\n",
    "print(\"Accuracy (Val):\", rf_val_acc)\n",
    "print(\"Classification Report (Val):\\n\", classification_report(y_val, rf_val_pred))\n",
    "print(\"Confusion Matrix (Val):\\n\", confusion_matrix(y_val, rf_val_pred))\n",
    "\n",
    "# Decide if we want to proceed to the test set:\n",
    "RF_VAL_THRESHOLD = 0.99  # Example threshold. Adjust as needed.\n",
    "\n",
    "if rf_val_acc < RF_VAL_THRESHOLD:\n",
    "    print(f\"\\n[WARNING] [RandomForest] Validation Accuracy {rf_val_acc:.4f} < {RF_VAL_THRESHOLD}.\")\n",
    "    print(\"We are NOT satisfied. Consider tuning hyperparameters, features, etc.\")\n",
    "    print(\"Skipping test evaluation for RandomForest.\\n\")\n",
    "else:\n",
    "    # -----------------------------------------------------------\n",
    "    # B.5) EVALUATE ON TEST SET IF VALIDATION IS GOOD\n",
    "    # -----------------------------------------------------------\n",
    "    rf_test_pred = final_rf.predict(X_test_sel_rf)\n",
    "    rf_test_acc = accuracy_score(y_test, rf_test_pred)\n",
    "    print(\"\\n=== [RandomForest] MODEL PERFORMANCE ON TEST SET ===\")\n",
    "    print(\"Accuracy (Test):\", rf_test_acc)\n",
    "    print(\"Classification Report (Test):\\n\", classification_report(y_test, rf_test_pred))\n",
    "    print(\"Confusion Matrix (Test):\\n\", confusion_matrix(y_test, rf_test_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPROVED MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= RANDOM FOREST PIPELINE WITH GRIDSEARCHCV =================\n",
      "\n",
      "\n",
      "[DEBUG] Starting RFE fit (RandomForest) on TRAIN ONLY... (this may take a while)\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "\n",
      "[DEBUG] RandomForest RFE Feature Ranking Results:\n",
      "0: amt | Support=True, Rank=1\n",
      "1: distance_km | Support=False, Rank=3\n",
      "2: age | Support=True, Rank=1\n",
      "3: city_pop | Support=True, Rank=1\n",
      "4: year | Support=False, Rank=4\n",
      "5: month | Support=True, Rank=1\n",
      "6: hour | Support=True, Rank=1\n",
      "7: day_of_week | Support=True, Rank=1\n",
      "8: gender_M | Support=False, Rank=2\n",
      "9: city_te | Support=True, Rank=1\n",
      "10: state_te | Support=True, Rank=1\n",
      "11: job_te | Support=True, Rank=1\n",
      "12: category_te | Support=True, Rank=1\n",
      "\n",
      "=== SELECTED FEATURES by RandomForest RFE ===\n",
      "   - amt\n",
      "   - age\n",
      "   - city_pop\n",
      "   - month\n",
      "   - hour\n",
      "   - day_of_week\n",
      "   - city_te\n",
      "   - state_te\n",
      "   - job_te\n",
      "   - category_te\n",
      "\n",
      "[DEBUG] Starting Grid Search for RandomForest...\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 6.0min\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time= 6.1min\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 6.1min\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 6.1min\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time= 6.2min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 85\u001b[0m\n\u001b[1;32m     75\u001b[0m grid_search_rf \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     76\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mrf_clf_grid,\n\u001b[1;32m     77\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m              \u001b[38;5;66;03m# Utilize all available CPU cores\u001b[39;00m\n\u001b[1;32m     82\u001b[0m )\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Perform Grid Search on the selected training set\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \u001b[43mgrid_search_rf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sel_rf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_sm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Best parameters and score from Grid Search\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[INFO] Best Parameters from Grid Search:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, grid_search_rf\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# PART B: RANDOM FOREST (for comparison) WITH GRIDSEARCHCV\n",
    "# ===========================================================\n",
    "print(\"\\n================= RANDOM FOREST PIPELINE WITH GRIDSEARCHCV =================\\n\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# B.1) IMPORT NECESSARY MODULES\n",
    "# -----------------------------------------------------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# B.2) RFE USING RANDOMFOREST ON TRAIN\n",
    "# -----------------------------------------------------------\n",
    "# Initialize the RandomForestClassifier for RFE\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100,       # Number of trees in the forest\n",
    "    random_state=42,        # Ensures reproducibility\n",
    "    n_jobs=-1                # Utilize all available CPU cores for parallel processing\n",
    ")\n",
    "\n",
    "# Initialize RFE with the RandomForestClassifier\n",
    "rf_rfe = RFE(\n",
    "    estimator=rf_clf,\n",
    "    n_features_to_select=10,  # Number of top features to select\n",
    "    step=1,                    # Number of features to remove at each iteration\n",
    "    verbose=1                  # Controls the verbosity: the higher, the more messages\n",
    ")\n",
    "\n",
    "print(\"\\n[DEBUG] Starting RFE fit (RandomForest) on TRAIN ONLY... (this may take a while)\")\n",
    "rf_rfe.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# Retrieve the support mask and ranking of features\n",
    "rf_support_mask = rf_rfe.support_\n",
    "rf_ranking = rf_rfe.ranking_\n",
    "\n",
    "print(\"\\n[DEBUG] RandomForest RFE Feature Ranking Results:\")\n",
    "for i, feat_name in enumerate(final_feature_names):\n",
    "    print(f\"{i}: {feat_name} | Support={rf_support_mask[i]}, Rank={rf_ranking[i]}\")\n",
    "\n",
    "# Extract the names of selected features\n",
    "rf_selected_features = [f for f, s in zip(final_feature_names, rf_support_mask) if s]\n",
    "print(\"\\n=== SELECTED FEATURES by RandomForest RFE ===\")\n",
    "for feat in rf_selected_features:\n",
    "    print(\"   -\", feat)\n",
    "\n",
    "# Transform the datasets to contain only the selected features\n",
    "X_train_sel_rf = rf_rfe.transform(X_train_sm)\n",
    "X_val_sel_rf   = rf_rfe.transform(X_val_enc)\n",
    "X_test_sel_rf  = rf_rfe.transform(X_test_enc)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# B.3) HYPERPARAMETER TUNING WITH GRIDSEARCHCV\n",
    "# -----------------------------------------------------------\n",
    "print(\"\\n[DEBUG] Starting Grid Search for RandomForest...\")\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],           # Number of trees in the forest\n",
    "    'max_depth': [15, 30],           # Maximum depth of each tree\n",
    "    'min_samples_split': [5, 10],           # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, ],             # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider when looking for the best split            s\n",
    "}\n",
    "\n",
    "# Initialize a new RandomForestClassifier for GridSearchCV\n",
    "rf_clf_grid = RandomForestClassifier(\n",
    "    random_state=42,  # Ensures reproducibility\n",
    "    n_jobs=-1          # Utilize all available CPU cores\n",
    ")\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf_clf_grid,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',    # Evaluation metric to optimize; can be changed based on your objective\n",
    "    cv=5,                  # 5-fold cross-validation\n",
    "    verbose=2,             # Controls the verbosity: the higher, the more messages\n",
    "    n_jobs=-1              # Utilize all available CPU cores\n",
    ")\n",
    "\n",
    "# Perform Grid Search on the selected training set\n",
    "grid_search_rf.fit(X_train_sel_rf, y_train_sm)\n",
    "\n",
    "# Best parameters and score from Grid Search\n",
    "print(\"\\n[INFO] Best Parameters from Grid Search:\\n\", grid_search_rf.best_params_)\n",
    "print(\"\\n[INFO] Best Cross-Validation Accuracy:\\n\", grid_search_rf.best_score_)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# B.4) TRAIN FINAL RANDOMFOREST ON SELECTED FEATURES (TRAIN ONLY)\n",
    "# -----------------------------------------------------------\n",
    "print(\"\\n[DEBUG] Training final RandomForest with best parameters on selected features (TRAIN ONLY)...\")\n",
    "\n",
    "# Retrieve the best estimator from Grid Search\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# Train the best RandomForestClassifier on the full training data\n",
    "best_rf.fit(X_train_sel_rf, y_train_sm)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# B.5) EVALUATE ON TRAIN SET FIRST (OVERFITTING CHECK)\n",
    "# -----------------------------------------------------------\n",
    "rf_train_pred = best_rf.predict(X_train_sel_rf)\n",
    "rf_train_acc  = accuracy_score(y_train_sm, rf_train_pred)\n",
    "\n",
    "print(\"\\n=== [RandomForest] MODEL PERFORMANCE ON TRAIN SET (WITH SMOTE) ===\")\n",
    "print(\"Accuracy (Train):\", rf_train_acc)\n",
    "print(\"Classification Report (Train):\\n\", classification_report(y_train_sm, rf_train_pred))\n",
    "print(\"Confusion Matrix (Train):\\n\", confusion_matrix(y_train_sm, rf_train_pred))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# B.6) EVALUATE ON VALIDATION SET\n",
    "# -----------------------------------------------------------\n",
    "rf_val_pred = best_rf.predict(X_val_sel_rf)\n",
    "rf_val_acc = accuracy_score(y_val, rf_val_pred)\n",
    "\n",
    "print(\"\\n=== [RandomForest] MODEL PERFORMANCE ON VALIDATION SET ===\")\n",
    "print(\"Accuracy (Val):\", rf_val_acc)\n",
    "print(\"Classification Report (Val):\\n\", classification_report(y_val, rf_val_pred))\n",
    "print(\"Confusion Matrix (Val):\\n\", confusion_matrix(y_val, rf_val_pred))\n",
    "\n",
    "# Decide if we want to proceed to the test set:\n",
    "RF_VAL_THRESHOLD = 0.99  # Example threshold. Adjust as needed.\n",
    "\n",
    "if rf_val_acc < RF_VAL_THRESHOLD:\n",
    "    print(f\"\\n[WARNING] [RandomForest] Validation Accuracy {rf_val_acc:.4f} < {RF_VAL_THRESHOLD}.\")\n",
    "    print(\"We are NOT satisfied. Consider tuning hyperparameters, features, etc.\")\n",
    "    print(\"Skipping test evaluation for RandomForest.\\n\")\n",
    "else:\n",
    "    # -----------------------------------------------------------\n",
    "    # B.7) EVALUATE ON TEST SET IF VALIDATION IS GOOD\n",
    "    # -----------------------------------------------------------\n",
    "    rf_test_pred = best_rf.predict(X_test_sel_rf)\n",
    "    rf_test_acc = accuracy_score(y_test, rf_test_pred)\n",
    "    print(\"\\n=== [RandomForest] MODEL PERFORMANCE ON TEST SET ===\")\n",
    "    print(\"Accuracy (Test):\", rf_test_acc)\n",
    "    print(\"Classification Report (Test):\\n\", classification_report(y_test, rf_test_pred))\n",
    "    print(\"Confusion Matrix (Test):\\n\", confusion_matrix(y_test, rf_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= RANDOM FOREST (RFE) =================\n",
      "\n",
      "\n",
      "[DEBUG] Starting RFE fit (RandomForest) on TRAIN ONLY...\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "\n",
      "[DEBUG] RandomForest RFE Feature Ranking Results:\n",
      "0: amt | Support=True, Rank=1\n",
      "1: distance_km | Support=False, Rank=3\n",
      "2: age | Support=True, Rank=1\n",
      "3: city_pop | Support=True, Rank=1\n",
      "4: year | Support=False, Rank=4\n",
      "5: month | Support=True, Rank=1\n",
      "6: hour | Support=True, Rank=1\n",
      "7: day_of_week | Support=True, Rank=1\n",
      "8: gender_M | Support=False, Rank=2\n",
      "9: city_te | Support=True, Rank=1\n",
      "10: state_te | Support=True, Rank=1\n",
      "11: job_te | Support=True, Rank=1\n",
      "12: category_te | Support=True, Rank=1\n",
      "\n",
      "=== SELECTED FEATURES by RandomForest RFE ===\n",
      "   - amt\n",
      "   - age\n",
      "   - city_pop\n",
      "   - month\n",
      "   - hour\n",
      "   - day_of_week\n",
      "   - city_te\n",
      "   - state_te\n",
      "   - job_te\n",
      "   - category_te\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"\\n================= RANDOM FOREST (RFE) =================\\n\")\n",
    "\n",
    "# 1) Baseline RF for RFE\n",
    "rf_clf_for_rfe = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 2) RFE initialization: select top 10 features\n",
    "rf_rfe = RFE(\n",
    "    estimator=rf_clf_for_rfe,\n",
    "    n_features_to_select=10,\n",
    "    step=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n[DEBUG] Starting RFE fit (RandomForest) on TRAIN ONLY...\")\n",
    "rf_rfe.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# 3) Inspect the feature rankings\n",
    "rf_support_mask = rf_rfe.support_\n",
    "rf_ranking = rf_rfe.ranking_\n",
    "\n",
    "print(\"\\n[DEBUG] RandomForest RFE Feature Ranking Results:\")\n",
    "for i, feat_name in enumerate(final_feature_names):\n",
    "    print(f\"{i}: {feat_name} | Support={rf_support_mask[i]}, Rank={rf_ranking[i]}\")\n",
    "\n",
    "# 4) Collect selected features\n",
    "rf_selected_features = [f for f, s in zip(final_feature_names, rf_support_mask) if s]\n",
    "print(\"\\n=== SELECTED FEATURES by RandomForest RFE ===\")\n",
    "for feat in rf_selected_features:\n",
    "    print(\"   -\", feat)\n",
    "\n",
    "# 5) Transform the datasets (train/val/test) to keep only selected features\n",
    "X_train_sel_rf = rf_rfe.transform(X_train_sm)\n",
    "X_val_sel_rf   = rf_rfe.transform(X_val_enc)\n",
    "X_test_sel_rf  = rf_rfe.transform(X_test_enc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= GRID SEARCH FOR RANDOM FOREST =================\n",
      "\n",
      "[DEBUG] Starting Grid Search on selected features (TRAIN ONLY)...\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.1s[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.1s\n",
      "\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 1/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.1s\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.1s[CV 2/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.1s\n",
      "\n",
      "[CV 3/3] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.1s\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.5min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.4min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.4min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.2min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.999 total time=10.5min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.5min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.4min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.2min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.999 total time=10.5min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.4min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.1min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.0min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.1min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.999 total time=10.4min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.4min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.999 total time=10.5min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.5min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.999 total time= 3.1min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.4min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.5min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.2min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.4min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.999 total time= 4.8min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.6min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.999 total time=10.8min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.7min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.4min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.5min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.7min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.9min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.4min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.6min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.4min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.999 total time=10.6min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.8min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.5min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.999 total time=10.6min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.5min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.4min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.3min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.5min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.999 total time=10.3min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.2min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.6min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.999 total time=10.7min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.7min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.6min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.4min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.5min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.4min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.9min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.4min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.5min\n",
      "[CV 3/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.999 total time=10.3min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.6min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.6min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.6min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.999 total time=10.4min\n",
      "[CV 2/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.3min\n",
      "[CV 1/3] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.4min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.2min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.4min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.4min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.4min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.4min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.3min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.6min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.999 total time=10.2min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.4min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.999 total time=10.2min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.999 total time=10.5min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.6min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.999 total time=10.4min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.4min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.3min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.4min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.2min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.5min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.2min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.6min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.999 total time= 2.8min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.4min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.1min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.0min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.999 total time= 5.0min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.6min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.0min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.0min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.2min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.6min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.999 total time= 2.7min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.0min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.1min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.5min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.999 total time= 9.9min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.999 total time= 5.0min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.999 total time= 9.7min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.999 total time= 9.7min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.6min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.999 total time= 2.6min\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=nan total time=   0.2s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=nan total time=   0.6s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.3s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.7s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.3s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.6s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.3s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=nan total time=   0.6s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.3s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.3s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.2s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.6s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.3s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.4s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=nan total time=   0.3s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.3s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.3s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.3s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.3s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.6s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.3s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.3s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.3s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=nan total time=   0.6s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.6s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.3s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.979 total time= 2.2min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.5min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.3min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.4min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.1min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.999 total time= 5.5min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.979 total time= 1.8min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.980 total time= 1.9min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.999 total time=10.0min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.980 total time= 1.8min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.979 total time= 3.6min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.979 total time= 3.7min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.980 total time= 3.7min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.980 total time= 2.0min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.979 total time= 1.9min\n",
      "[CV 1/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.7min\n",
      "[CV 2/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.7min\n",
      "[CV 3/3] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.999 total time=10.9min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.979 total time= 4.1min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.980 total time= 7.8min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.979 total time= 4.2min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.980 total time= 7.7min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.980 total time= 7.7min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.979 total time= 1.9min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.980 total time= 4.1min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.979 total time= 1.9min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.979 total time= 1.9min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.979 total time= 3.8min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.979 total time= 1.9min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.979 total time= 3.5min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.980 total time= 3.5min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.980 total time= 7.5min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.979 total time= 1.6min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.979 total time= 1.6min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.980 total time= 7.3min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.980 total time= 7.4min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.979 total time= 2.0min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.980 total time= 3.9min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.979 total time= 3.8min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.979 total time= 7.2min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.980 total time= 7.2min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.979 total time= 3.8min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.980 total time= 7.2min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.978 total time= 1.9min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.980 total time= 1.9min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.979 total time= 1.9min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.980 total time= 3.7min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.980 total time= 3.7min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.979 total time= 3.7min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.979 total time= 7.4min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.979 total time= 7.4min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.980 total time= 7.5min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.979 total time= 2.1min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.979 total time= 2.1min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.978 total time= 1.9min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.979 total time= 3.9min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.979 total time= 4.0min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.980 total time= 7.5min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.980 total time= 7.6min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.980 total time= 3.9min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.981 total time= 7.6min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.978 total time= 1.9min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.979 total time= 1.9min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.980 total time= 3.8min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.979 total time= 3.8min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.979 total time= 3.8min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.978 total time= 1.9min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.979 total time= 7.6min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.980 total time= 7.4min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.980 total time= 7.4min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.979 total time= 2.1min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.978 total time= 2.2min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.979 total time= 4.0min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.979 total time= 7.7min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.979 total time= 4.0min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.980 total time= 4.0min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.978 total time= 1.9min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.979 total time= 7.6min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.980 total time= 7.5min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.979 total time= 1.7min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.979 total time= 1.8min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.979 total time= 3.5min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.979 total time= 3.6min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.980 total time= 3.6min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.979 total time= 1.9min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.979 total time= 7.4min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.979 total time= 7.5min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.980 total time= 7.2min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.979 total time= 1.9min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.980 total time= 1.9min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.979 total time= 4.0min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.979 total time= 4.0min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.980 total time= 2.1min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.980 total time= 4.0min\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.979 total time= 7.7min\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.979 total time= 7.7min\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.980 total time= 7.6min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.979 total time= 1.9min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.980 total time= 1.9min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.979 total time= 3.7min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.979 total time= 2.0min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.979 total time= 3.8min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.980 total time= 3.6min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.980 total time= 7.4min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.980 total time= 7.4min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.980 total time= 7.4min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.979 total time= 1.6min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.979 total time= 1.7min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.979 total time= 2.2min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.979 total time= 3.8min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.979 total time= 4.1min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.980 total time= 4.0min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.980 total time= 7.2min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.980 total time= 7.2min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.980 total time= 7.2min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.979 total time= 1.6min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.979 total time= 1.9min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.979 total time= 1.9min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.980 total time= 3.4min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.979 total time= 3.4min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.979 total time= 3.6min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.979 total time= 7.3min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.980 total time= 7.3min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.980 total time= 7.3min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.978 total time= 1.4min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.980 total time= 1.9min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.979 total time= 2.0min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.980 total time= 3.8min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.979 total time= 7.3min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.979 total time= 3.8min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.980 total time= 3.8min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.979 total time= 7.3min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.980 total time= 7.3min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.979 total time= 1.8min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.979 total time= 1.9min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.978 total time= 2.0min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.979 total time= 3.8min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.979 total time= 3.8min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.980 total time= 7.4min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.980 total time= 3.8min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.980 total time= 7.5min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.981 total time= 7.5min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.978 total time= 2.3min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.979 total time= 2.3min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.978 total time= 1.8min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.979 total time= 4.1min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.979 total time= 7.8min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.979 total time= 4.1min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.980 total time= 4.1min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.980 total time= 7.8min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.980 total time= 7.7min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.978 total time= 1.9min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.979 total time= 2.0min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.979 total time= 3.8min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.979 total time= 3.8min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.980 total time= 3.8min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.978 total time= 1.9min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.979 total time= 7.8min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.979 total time= 7.8min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.980 total time= 7.3min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.979 total time= 1.9min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.979 total time= 1.9min\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=nan total time=   0.7s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.3s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.4s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.6s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=nan total time=   0.6s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=nan total time=   0.2s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.6s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.4s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.6s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=nan total time=   0.6s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.2s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.2s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.7s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=nan total time=   0.6s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.3s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.6s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.3s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.7s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.7s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.3s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.4s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=nan total time=   0.6s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.4s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.6s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.5s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.6s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.4s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.4s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.4s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.5s\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.979 total time= 3.7min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.979 total time= 3.7min\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.980 total time= 3.7min\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.979 total time= 7.4min\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.979 total time= 7.4min\n",
      "[CV 1/3] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.998 total time= 2.2min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "print(\"\\n================= GRID SEARCH FOR RANDOM FOREST =================\\n\")\n",
    "\n",
    "# Define a small hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize the RF classifier (we'll rely on the param_grid to tune it)\n",
    "rf_for_grid = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Start timer to measure GridSearch execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# We will do 3-fold CV here for speed. Increase if you want more robust estimates.\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_for_grid,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',      # or f1, roc_auc, etc.\n",
    "    cv=3,                    # 3-fold cross-validation\n",
    "    n_jobs=-1,               # parallelize\n",
    "    verbose=3                # Enable verbosity to see progress\n",
    ")\n",
    "\n",
    "print(\"[DEBUG] Starting Grid Search on selected features (TRAIN ONLY)...\")\n",
    "grid_search.fit(X_train_sel_rf, y_train_sm)\n",
    "\n",
    "# Measure the time taken for the grid search\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\n[DEBUG] Grid Search Completed in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "print(\"\\n[DEBUG] Best Grid Search Params:\", grid_search.best_params_)\n",
    "print(\"[DEBUG] Best Grid Search Score :\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [Tuned RandomForest] MODEL PERFORMANCE ON TRAIN SET (WITH SMOTE) ===\n",
      "Accuracy (Train): 0.9795882765525056\n",
      "Classification Report (Train):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    834055\n",
      "           1       0.98      0.98      0.98    834055\n",
      "\n",
      "    accuracy                           0.98   1668110\n",
      "   macro avg       0.98      0.98      0.98   1668110\n",
      "weighted avg       0.98      0.98      0.98   1668110\n",
      "\n",
      "Confusion Matrix (Train):\n",
      " [[820322  13733]\n",
      " [ 20316 813739]]\n",
      "\n",
      "=== [Tuned RandomForest] MODEL PERFORMANCE ON VALIDATION SET ===\n",
      "Accuracy (Val): 0.9834727295268795\n",
      "Classification Report (Val):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    104257\n",
      "           1       0.24      0.89      0.38       600\n",
      "\n",
      "    accuracy                           0.98    104857\n",
      "   macro avg       0.62      0.94      0.69    104857\n",
      "weighted avg       1.00      0.98      0.99    104857\n",
      "\n",
      "Confusion Matrix (Val):\n",
      " [[102590   1667]\n",
      " [    66    534]]\n",
      "\n",
      "=== [Tuned RandomForest] MODEL PERFORMANCE ON TEST SET ===\n",
      "Accuracy (Test): 0.9828911480287628\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    104257\n",
      "           1       0.24      0.91      0.38       601\n",
      "\n",
      "    accuracy                           0.98    104858\n",
      "   macro avg       0.62      0.95      0.68    104858\n",
      "weighted avg       1.00      0.98      0.99    104858\n",
      "\n",
      "Confusion Matrix (Test):\n",
      " [[102519   1738]\n",
      " [    56    545]]\n"
     ]
    }
   ],
   "source": [
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on TRAIN (SMOTE) to check for overfitting\n",
    "rf_train_pred = best_rf.predict(X_train_sel_rf)\n",
    "rf_train_acc  = accuracy_score(y_train_sm, rf_train_pred)\n",
    "\n",
    "print(\"\\n=== [Tuned RandomForest] MODEL PERFORMANCE ON TRAIN SET (WITH SMOTE) ===\")\n",
    "print(\"Accuracy (Train):\", rf_train_acc)\n",
    "print(\"Classification Report (Train):\\n\", classification_report(y_train_sm, rf_train_pred))\n",
    "print(\"Confusion Matrix (Train):\\n\", confusion_matrix(y_train_sm, rf_train_pred))\n",
    "\n",
    "# Evaluate on VALIDATION SET\n",
    "rf_val_pred = best_rf.predict(X_val_sel_rf)\n",
    "rf_val_acc  = accuracy_score(y_val, rf_val_pred)\n",
    "\n",
    "print(\"\\n=== [Tuned RandomForest] MODEL PERFORMANCE ON VALIDATION SET ===\")\n",
    "print(\"Accuracy (Val):\", rf_val_acc)\n",
    "print(\"Classification Report (Val):\\n\", classification_report(y_val, rf_val_pred))\n",
    "print(\"Confusion Matrix (Val):\\n\", confusion_matrix(y_val, rf_val_pred))\n",
    "\n",
    "# Decide if you want to check TEST set based on validation accuracy\n",
    "RF_VAL_THRESHOLD = 0.90  # example threshold - adjust as needed\n",
    "if rf_val_acc < RF_VAL_THRESHOLD:\n",
    "    print(f\"\\n[WARNING] [RandomForest] Validation Accuracy {rf_val_acc:.4f} < {RF_VAL_THRESHOLD}.\")\n",
    "    print(\"We are NOT satisfied. Consider tuning again or adding more features.\")\n",
    "    print(\"Skipping test evaluation for RandomForest.\\n\")\n",
    "else:\n",
    "    # Evaluate on TEST SET\n",
    "    rf_test_pred = best_rf.predict(X_test_sel_rf)\n",
    "    rf_test_acc  = accuracy_score(y_test, rf_test_pred)\n",
    "    print(\"\\n=== [Tuned RandomForest] MODEL PERFORMANCE ON TEST SET ===\")\n",
    "    print(\"Accuracy (Test):\", rf_test_acc)\n",
    "    print(\"Classification Report (Test):\\n\", classification_report(y_test, rf_test_pred))\n",
    "    print(\"Confusion Matrix (Test):\\n\", confusion_matrix(y_test, rf_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m learning_curve\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# We'll use the best random forest from the grid search\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m best_rf \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Evaluate learning curve on the training set (with selected features)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m train_sizes, train_scores, val_scores \u001b[38;5;241m=\u001b[39m learning_curve(\n\u001b[1;32m     10\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mbest_rf,\n\u001b[1;32m     11\u001b[0m     X\u001b[38;5;241m=\u001b[39mX_train_sel_rf,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     train_sizes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# 5 points from 10% to 100% of training data\u001b[39;00m\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# We'll use the best random forest from the grid search\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate learning curve on the training set (with selected features)\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    estimator=best_rf,\n",
    "    X=X_train_sel_rf,\n",
    "    y=y_train_sm,\n",
    "    cv=3,               # same # of folds as GridSearch (can adjust)\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5)  # 5 points from 10% to 100% of training data\n",
    ")\n",
    "\n",
    "# Compute mean and std for plotting\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std  = np.std(train_scores, axis=1)\n",
    "val_mean   = np.mean(val_scores, axis=1)\n",
    "val_std    = np.std(val_scores, axis=1)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training Score')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, val_mean, 'o-', color='red', label='Validation Score')\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='red')\n",
    "\n",
    "plt.title('Learning Curve (Tuned RandomForest)')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
